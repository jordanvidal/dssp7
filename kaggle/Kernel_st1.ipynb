{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structure.......................\n",
      "Training data.... (252108, 3)\n",
      "Unique store id in training data 829\n",
      "Id data.... (150, 2)\n",
      "Air store data.... (829, 5) & unique- (829,)\n",
      "Hpg store data.... (63, 6) & unique- (63,)\n",
      "Air reserve data.... (92378, 4) & unique- (314,)\n",
      "Hpg reserve data.... (28183, 5) & unique- (150,)\n",
      "20.1597\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import ensemble, neighbors, linear_model, metrics, preprocessing\n",
    "from datetime import datetime\n",
    "import glob, re\n",
    "import time, datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from JdPaletto & the1owl1\n",
    "# JdPaletto - https://www.kaggle.com/jdpaletto/surprised-yet-part2-lb-0-503?scriptVersionId=1867420\n",
    "# the1owl1 - https://www.kaggle.com/the1owl/surprise-me\n",
    "start1 =time.time()\n",
    "data = {\n",
    "    'tra': pd.read_csv('data/air_visit_data.csv.zip', compression=\"zip\"),\n",
    "    'as': pd.read_csv('data/air_store_info.csv.zip', compression=\"zip\"),\n",
    "    'hs': pd.read_csv('data/hpg_store_info.csv.zip', compression=\"zip\"),\n",
    "    'ar': pd.read_csv('data/air_reserve.csv.zip', compression=\"zip\"),\n",
    "    'hr': pd.read_csv('data/hpg_reserve.csv.zip', compression=\"zip\"),\n",
    "    'id': pd.read_csv('data/store_id_relation.csv.zip', compression=\"zip\"),\n",
    "    'tes': pd.read_csv('data/sample_submission.csv.zip', compression=\"zip\"),\n",
    "    'hol': pd.read_csv('data/date_info.csv.zip', compression=\"zip\").rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])# bring air id to hpg reserve data\n",
    "data['hs'] = pd.merge(data['hs'], data['id'], how='inner', on=['hpg_store_id'])# bring air id to hpg stores\n",
    "\n",
    "print('Data structure.......................')\n",
    "print('Training data....',data['tra'].shape)\n",
    "print('Unique store id in training data',len(data['tra']['air_store_id'].unique()))\n",
    "print('Id data....',data['id'].shape)\n",
    "print('Air store data....',data['as'].shape,'& unique-',data['as']['air_store_id'].unique().shape)\n",
    "print('Hpg store data....',data['hs'].shape,'& unique-',data['hs']['hpg_store_id'].unique().shape)\n",
    "print('Air reserve data....',data['ar'].shape,'& unique-',data['ar']['air_store_id'].unique().shape)\n",
    "print('Hpg reserve data....',data['hr'].shape,'& unique-',data['hr']['air_store_id'].unique().shape)\n",
    "      \n",
    "#converting datetime to date for reservation data\n",
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_hour'] = data[df]['visit_datetime'].dt.hour\n",
    "    data[df]['visit_date'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_hour'] = data[df]['reserve_datetime'].dt.hour\n",
    "    data[df]['reserve_date'] = data[df]['reserve_datetime'].dt.date\n",
    "    \n",
    "    data[df+'_hour'] = data[df]#keeping original\n",
    "        \n",
    "    #calculate reserve time difference and summarizing ar,hr to date\n",
    "    data[df]['reserve_day_'+df] = data[df].apply(\n",
    "        lambda r: (r['visit_date'] - r['reserve_date']).days, axis=1)\n",
    "    data[df] = data[df].groupby(['air_store_id','visit_date'], as_index=False)[[\n",
    "        'reserve_day_'+df, 'reserve_visitors']].sum().rename(columns={'reserve_visitors':'reserve_visitors_'+df})\n",
    "    \n",
    "#breaking down dates on training data & summarizing \n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['day'] = data['tra']['visit_date'].dt.day\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.weekday\n",
    "data['tra']['dow_name'] = data['tra']['visit_date'].dt.weekday_name\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['week'] = data['tra']['visit_date'].dt.week\n",
    "data['tra']['quarter'] = data['tra']['visit_date'].dt.quarter\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "data['tra']['year_mth'] = data['tra']['year'].astype(str)+'-'+data['tra']['month'].astype(str)\n",
    "\n",
    "\n",
    "#extracting store id and date info from test data\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['day'] = data['tes']['visit_date'].dt.day\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.weekday\n",
    "data['tes']['dow_name'] = data['tes']['visit_date'].dt.weekday_name\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['week'] = data['tes']['visit_date'].dt.week\n",
    "data['tes']['quarter'] = data['tes']['visit_date'].dt.quarter\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n",
    "data['tes']['year_mth'] = data['tes']['year'].astype(str)+'-'+data['tes']['month'].astype(str)\n",
    "\n",
    "#extract unique stores based on test data and populate dow 1 to 6\n",
    "unique_stores = data['tes']['air_store_id'].unique()#extract unique stores id from test data\n",
    "\n",
    "store_7days = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) \n",
    "                    for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "store_sum = pd.DataFrame({'air_store_id': unique_stores})\n",
    "\n",
    "# mapping train data dow to stores(test data) - min, mean, median, max, count \n",
    "tmp = data['tra'].groupby(['air_store_id'], as_index=False)[\n",
    "    'visitors'].sum().rename(columns={'visitors':'total_visitors'})\n",
    "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id']) \n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)[\n",
    "    'visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)[\n",
    "    'visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)[\n",
    "    'visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)[\n",
    "    'visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id','dow']) \n",
    "# map stores(test) to store genre and location detail\n",
    "store_7days = pd.merge(store_7days, data['as'], how='left', on=['air_store_id']) \n",
    "#map to hpg genre and area\n",
    "store_7days = pd.merge(store_7days, data['hs'][['air_store_id','hpg_genre_name','hpg_area_name']], \n",
    "                       how='left', on=['air_store_id']) \n",
    "\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "\n",
    "hf=data['hol']['holiday_flg']\n",
    "dw=data['hol']['day_of_week']\n",
    "data['hol']['long_wknd']=0\n",
    "\n",
    "for i in range(len(data['hol'])):\n",
    "    if (hf[i]==1)&(dw[i]=='Friday'):\n",
    "        data['hol']['long_wknd'][i]=1\n",
    "        data['hol']['long_wknd'][i+1]=1\n",
    "        data['hol']['long_wknd'][i+2]=1\n",
    "          \n",
    "    if (hf[i]==1)&(dw[i]=='Monday'):\n",
    "        data['hol']['long_wknd'][i]=1\n",
    "        data['hol']['long_wknd'][i-1]=1\n",
    "        data['hol']['long_wknd'][i-2]=1\n",
    "\n",
    "\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n",
    "train = pd.merge(train, store_7days, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(test, store_7days, how='left', on=['air_store_id','dow'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "\n",
    "#col = [c for c in train if c not in ['id', 'air_store_id','visit_date','visitors']]\n",
    "\n",
    "#calculate qoq\n",
    "qoq= train.groupby(['air_store_id','year','quarter'])['visitors'].sum()\n",
    "qoq=qoq.unstack(0)\n",
    "qoq=pd.DataFrame(qoq.to_records())\n",
    "qoq=qoq.transpose()\n",
    "qoq.drop(['year','quarter'],inplace=True)\n",
    "qoq['2016Q2']=qoq[1]/qoq[0]*100\n",
    "qoq['2016Q3']=qoq[2]/qoq[1]*100\n",
    "qoq['2016Q4']=qoq[3]/qoq[2]*100\n",
    "qoq['2017Q1']=qoq[4]/qoq[3]*100\n",
    "lst=['2016Q2','2016Q3','2016Q4','2017Q1']\n",
    "qoq=qoq[lst]\n",
    "qoq['qoq_count']=qoq.apply(lambda x: x.count(), axis=1) \n",
    "qoq['qoq_growth']=qoq.apply(lambda x: x[x>100].count(), axis=1)\n",
    "qoq['qoq_growth_pct'] = round(qoq['qoq_growth'] /qoq['qoq_count'],2)\n",
    "qoq.index.names=['air_store_id']\n",
    "qoq.reset_index(inplace=True)\n",
    "\n",
    "train=pd.merge(train, qoq, how='left', on='air_store_id')\n",
    "\n",
    "train = train.fillna(0) #change to one for algo training\n",
    "test = test.fillna(0)\n",
    "#df=df.rename(columns = {'two':'new_name'})\n",
    "train['v_no_reservation']=train['visitors']-train['reserve_visitors_ar']-train['reserve_visitors_hr']\n",
    "print(round(time.time()-start1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
