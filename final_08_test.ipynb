{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from datetime import datetime\n",
    "from xgboost import XGBRegressor\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn import preprocessing, ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.basicConfig(filename='report/output.log', level=logging.DEBUG, format='%(asctime)s :: %(levelname)s :: %(message)s',datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "logging.info('DATA IMPORT...')\n",
    "data = {\n",
    "    'tra': pd.read_csv('data/air_visit_data.csv.zip', compression=\"zip\"),\n",
    "    'as': pd.read_csv('data/air_store_info.csv.zip', compression=\"zip\"),\n",
    "    'hs': pd.read_csv('data/hpg_store_info.csv.zip', compression=\"zip\"),\n",
    "    'ar': pd.read_csv('data/air_reserve.csv.zip', compression=\"zip\"),\n",
    "    'hr': pd.read_csv('data/hpg_reserve.csv.zip', compression=\"zip\"),\n",
    "    'id': pd.read_csv('data/store_id_relation.csv.zip', compression=\"zip\"),\n",
    "    'tes': pd.read_csv('data/sample_submission.csv.zip', compression=\"zip\"),\n",
    "    'hol': pd.read_csv('data/date_info.csv.zip', compression=\"zip\").rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "\n",
    "logging.info('DATA CLEANING + FE...')\n",
    "for df in ['ar','hr']:\n",
    "    #convert to datetime + creation de \"reserve_datetime_diff\"\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    # Ajout de la somme (tmp1) et de la moyenne (tmp2) du nombre de visiteurs et de reserve_datetime_diff par visites    \n",
    "    tmp1 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])\n",
    "\n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n",
    "\n",
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "\n",
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) \n",
    "\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n",
    "#Label encoder pour les air_genre_name and air_area_name\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(10):\n",
    "    stores['air_genre_name'+str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    stores['air_area_name'+str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "\n",
    "#creation of train and test by merging train/test and stores dataset\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n",
    "train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "\n",
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)\n",
    "\n",
    "#Calcul de la somme, moyenne du nombre de visiteurs + moyenne du nombres de jours d'ecart entre reservation et visite au restaurant\n",
    "\n",
    "\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2\n",
    "\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2'] = lbl.transform(test['air_store_id'])\n",
    "\n",
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 117.366\n",
      "test error: 126.228\n"
     ]
    }
   ],
   "source": [
    "y = train.pop('visitors')\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[col], y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logging.info('0. Linear Regression')\n",
    "lm = LinearRegression().fit(X_train, y_train)\n",
    "train_error_lm = round(np.sqrt(mean_squared_error(y_train, lm.predict(X_train))), 3)\n",
    "test_error_lm = round(np.sqrt(mean_squared_error(y_test, lm.predict(X_test))), 3)\n",
    "print(\"train error: {}\".format(train_error_lm))\n",
    "print(\"test error: {}\".format(test_error_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test):\n",
    "    p_test = model.predict_proba(X_test)\n",
    "    return mean_squared_error(y_test, p_test.argmax(axis=1))\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=1.0, n_jobs=4)\n",
    "logging.info('1. LogisticRegression - start fit')\n",
    "model.fit(X_train, y_train)\n",
    "logging.info('1. LogisticRegression - start predict')\n",
    "model.predict(X_test)\n",
    "score_lr = test_model(model, X_test, y_test)\n",
    "print('Logistic Regression score: {}'.format(score_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1)\n",
    "logging.info('2. RandomForestRegressor- start fit')\n",
    "rf.fit(X_train, y_train)\n",
    "logging.info('2. RandomForestRegressor- start predict')\n",
    "rf.predict(X_test)\n",
    "train_error_rf = round(mean_squared_error(y_train, rf.predict(X_train)), 3)\n",
    "test_error_rf = round(mean_squared_error(y_test, rf.predict(X_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('RandomForest feature importance: {}'.format(rf.feature_importances_))\n",
    "logging.info('2. Feature importances...')\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "dtrain = xgboost.DMatrix(train[col], label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(train[col].shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AVANT\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(train[col].shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(train[col].shape[1]), indices)\n",
    "plt.xlim([-1, train[col].shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
